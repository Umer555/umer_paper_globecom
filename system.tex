\section{Proposed System}
\label{sec:system}

\begin{table*}[!htbp]
\caption{ Notations used in mathematical and descriptive details  }
\label{tab:notations}
\begin{center}\begin{tabular}{{ |l |l |l }}
    \hline
    Notation & Description\\
    \hline\hline
\vspace*{\fill}\centering $\mathcal{F}$ & Confidential file that needs to
     be outsourced \\\hline
\vspace*{\fill} \centering $\mathcal{K}\omega$ & List of keywords in a data file
$\mathcal{F}$ \\\hline \vspace*{\fill} \centering $f\omega$ & Frequency of a keyword $k\omega$ \\\hline
\vspace*{\fill} \centering $\mathcal{L}$ & Allowed keyword length for extraction
of list of keywords from data \\\hline
\vspace*{\fill} \centering $\mathcal{I}$ & Index file having encrypted bloom filter for each keyword, frequency and number of 1ns as index entries \\\hline
\vspace*{\fill} \centering $\mathcal{E}_h$ , $\mathcal{D}_h$
     & Homomorphic encryption and decryption functions \\\hline
\vspace*{\fill} \centering$\mathcal{E}_S$ , $\mathcal{D}_S$ & Symmetric
    encryption and decryption functions \\\hline
\vspace*{\fill} \centering $\sigma_{pk}$ , $\sigma_{sk}$ & Homomorphic
    encryption public and private keys \\\hline
\vspace*{\fill} \centering$\mathcal{K}_S$ & Symmetric encryption and
    decryption keys. It is used to encrypt the data file. \\\hline
\vspace*{\fill} \centering$\mathcal{S}_q$ & Similarity score of a query
\\\hline
\vspace*{\fill} \centering$\mathcal{R}_q$ & Compressed resultant term after bloom filter matching
\\\hline
\vspace*{\fill} \centering$\mathcal{M}_q$ & Uncompressed resultant term after bloom filter matching
\\\hline
\vspace*{\fill} \centering$\mathcal{BF}_i$ & i'th encrypted bit of bloom filter $\mathcal{BF}$
\\\hline
\vspace*{\fill} \centering $\mathcal{O}_b$ & Number of 1 bits in a bloom filter
\\\hline
\end{tabular}
\end{center}

\end{table*}


Before diving into a description of how the system
is designed and implemented, we discuss some of our assumptions
about the system and the threat model. Then we will describe the main
steps involved in the initial index generation
and then the actual search process over encrypted data.

\subsection{System Model}

Entities involved in the proposed system are the data owner, CSP and end user.
A data owner is an entity who wants its confidential data to be stored in cloud storage with the capability of privacy-aware searching. 
A CSP hosts public cloud storage services for its subscribers on 
a pay-as-you-use model. The end user is an entity that will perform searches on the 
encrypted data stored in the cloud. The end user can submit search queries 
to the CSP, which evaluates the queries and returns results back to the user. 
However, during query evaluation, the CSP should not be able to learn anything about the query, 
the stored data or the matching results.

\subsection{Threat Model}

The data owner and end user are considered trusted entities while CSP 
is considered as an untrusted entity because it is maintained by an 
arbitrary third party. Data communication between the end user and CSP should 
be considered as untrusted as all requests are routed via the open Internet. 
The CSP hosts the encrypted data file ($\mathcal{F}$) and the encrypted index ($\mathcal{I}$). 
As they are encrypted, the CSP cannot learn any information regarding $\mathcal{F}$ and $\mathcal{I}$. 
Query evaluation is done by CSP homomorphically: that is, the CSP performs 
evaluation over encrypted text of $\mathcal{I}$ and encrypted user query, 
so it is neither able to learn anything about the matched results, nor
can it relate any subsequent queries from other users. 

\subsection{Assumptions and Notations}

We ignore the key exchange mechanism between the data owner and the end users, assuming
that it happens using secure out-of-band channels.
Table \ref{tab:notations} illustrates the notations that we use in order to explain
the details of our proposed approach.


\subsection{Index Generation}

The data owner generates an encrypted index on the client side to facilitate
subsequent searches. At a high level, the index is generated by creating a 
\textit{sliding window bloom filter} which is then encrypted using the Pascal Paillier
homomorphic encryption algorithm~\cite{pascal}. 

The sliding window bloom filter (SWBF) is a special type of bloom filter
for which a window size is defined, and based on that
window size, a keyword is sliced and mapped to the bloom filter. For example,
suppose we have a word ``cloud" and a window size of 2. The word will then be
sliced into ``cl", ``lo", ``ou", and ``ud" and each of these slices will be 
independently mapped to the bloom filter. This filter enables us to achieve
 a partial matching even if the requested keyword does not match
 completely.

\begin{algorithm}[b!]
\KwIn{A collection of text files $C = \langle \mathcal{F}_1, \mathcal{F}_2, \ldots,
\mathcal{F}_n \rangle$}
\KwOut{Index files $I = \langle \mathcal{I}_1, \mathcal{I}_2, \ldots,
\mathcal{I}_n \rangle$ for each text file  in $C$}
$ \forall \mathcal{F}_i \in \langle \mathcal{F}_1, \mathcal{F}_2, \ldots,
\mathcal{F}_n \rangle$\;
\While{$\mathcal{F}_i \in  C $}{
  $\mathcal{K}\omega \gets extractAllKeywords (\mathcal{F}_i)$\;
  $\forall k\omega_j \in \mathcal{K}\omega $\;
          \While{$k\omega_j \in \mathcal{K}\omega$}{
            $SWBF \gets createSWBF (k\omega_j)$\;
            $f_j \gets getKeywordFrequency (k\omega_j) $\;
                $\mathcal{O}_b \gets getOnes (\mathcal{BF}_j) $\;
            $\forall bf_k \in SWBF $\;
                \While{$bf_k \in SWBF$}{
                        $\mathcal{BF}_k \gets \mathcal{E}_h (\sigma_{pk}, bf_k) $\;
                        $IndexEntry \gets IndexEntry,\mathcal{BF}_k $\;
                        $bf_k \gets getNextBit (SWBF) $\;
                }
                $IndexEntry \gets IndexEntry,f_j, \mathcal{O}_b $\;
                $\mathcal{I}_j \gets writeToIndexFile (IndexEntry) $\;
                $\mathcal{I} \gets \mathcal{I}, \mathcal{I}_j $\;
                $k\omega_j \gets getNextKeyword (\mathcal{K}) $\;
          }
  $\mathcal{F}_i \gets getNextFile (C) $\;
}
\Return{$\mathcal{I}$}\;
 \caption{Index Creation}
 \label{algo:IndexCreation}
\end{algorithm}

Algorithm~\ref{algo:IndexCreation} describes the indexing procedure.
For each file to be uploaded to the server, a separate index file is generated. The index
file contains one index entry per keyword. To generate the index file, a sliding window bloom
filter is updated for each keyword and the number of 1 bits in the bloom filter are noted.
Each bit of the bloom filter is then encrypted using the Pascal Paillier algorithm, and written to 
the index entry along with frequency and number of 1 bits.
At the end of this process, each index entry $\mathcal{I}_i$ in an index file $\mathcal{I}$ has
the structure: 
\begin{equation}
\mathcal{I}_i = \mathcal{BF}_i, f\omega,\mathcal{O}_b
  \label{eq: indexEntry}
\end{equation} 

where $\mathcal{O}_b$ is the number of 1's in the bloom filter
$\mathcal{BF}_i$ and $\mathcal{BF}_i$ is consisting of n bits
$\mathcal{BF}_i= \mathcal{BF}_1,\mathcal{BF}_2, \ldots ,\mathcal{BF}_n$.

Once the encrypted index file has been generated, it is uploaded to the cloud along with the data files.
The data files are encrypted using a symmetric encryption algorithm, as they will not be used during the
search process.

\subsection{Search Process}

To start the search process, the user first generates a query through a similar process as index creation. 
Each of the user's specified keywords are used to generate sliding window bloom filters, whose bits are then
encrypted using the public key $\sigma_{pk}$ of the Pascal Paillier algorithm. 
Note that this process takes place on the end user's machine. After encryption, 
the query (comprising the encrypted bloom filters) is sent to the cloud for terms matching.

On receiving a query, the CSP matches the incoming query with the index entries of 
the files it is hosting. For a perfect match, all of the corresponding bits of the index 
and query bloom filters need to match. However, since both the query and the index
bloom filters are encrypted, simple matching is not possible. Furthermore, encrypting the
same plaintext repeatedly results in completely different ciphertexts, which improves
privacy and security but makes matching difficult.

Fortunately, homomorphic encryption provides a way to perform mathematical operations 
over ciphertext. Since our bloom filter entries are encrypted using Pascal Paillier homomorphic
encryption, we can just multiply their ciphertexts, which when decrypted, yields the sum of
the plaintexts~\cite{pascal}. The sum of the bits will be either $0$,$1$ or $2$ after decryption.
The twos in the decrypted output then represent the matched
bits and the ones represent the unmatched bits. Then, a similarity score
can be estimated as the ratio of twos to ones in the decrypted result.

Note that decryption of this result will require users to have the private Pascal 
Paillier key. Thus, only authorized users who have received the private key from the
data owner can actually decrypt the results.

\subsection{Compressing Search Results}

Once the encrypted index entries and the query have been multiplied together, 
we can simply return these products back to the client. The client can then decrypt the products to get the
sums and compute similarity scores. While this straightforward approach works and
is used by many existing systems (for example, in ~\cite{zeehan}), it is extremely
inefficient.
In particular, if there are many documents and keywords in the cloud dataset, this
will result in a huge amount of data to be communicated back to the user. Specifically,
the product of the query and the encrypted index entry for \textit{every} keyword in the dataset will be returned
to the client. This will not only increase the response time over the network, but
also the cost of cloud computing for the data owner, since network usage is billed
by most cloud service providers.

In order to reduce this communication cost overhead, we devise a method by which
we are able to reduce this cost by over $95\%$. Based on the insight that each returned
index entry consists only of $0$s, $1$s or $2$s, we
define a polynomial $\mathcal{P}$ given by \eqref{eq: polynomial}. 
\begin{equation}
\mathcal{P} = {a}^0\cdot\mathcal{BF}_1 + {a}^1\cdot\mathcal{BF}_2 +
{a}^2\cdot\mathcal{BF}_3 + \ldots + {a}^{n-1}\cdot\mathcal{BF}_n
  \label{eq: polynomial}
\end{equation}
where ${a} \in \langle 3,5,7 \cdots \rangle $, $\mathcal{BF}_i$  are the
Paillier sums of the corresponding bits of an index entry and represent variables for
the polynomial $\mathcal{P}$ and $\mathcal{BF}_i \in \langle 0,1,2 \rangle $. We
used ${a}=3$ as it yields smaller sums and less computaion.

The sum of this polynomial $\mathcal{P}$ is the resultant compressed term which we return back
to client application:

\begin{equation}
\mathcal{R}_q = \sum_{i=0}^{n-1} {a}^{i}\cdot\mathcal{BF}_i
\label{eq:compressed}
\end{equation}

From \eqref{eq:compressed} we get a single compressed term $\mathcal{R}_q$
whose size is the size of the Pascal Paillier key. 
This multiplication by constants and addition is again possible 
because our bloom filter entries are encrypted using Pascal Paillier homomorphic
encryption. Therefore, if after decryption, we want the product of the plaintext with a constant, we
just need to exponentiate the ciphertext by that constant~\cite{pascal}.

This means that irrespective of the size
of the bloom filter,
we will always return a single number back to the client. The client can then
decompress it to find out the original Paillier sums using the routine
specified in Algorithm \ref{algo:decomp}. In short, this algorithm works correctly because every
$\mathcal{BF}_i$ is at most 2 and $ {a}^{n} > 2\sum_{j=0}^{n-1} {a}^{j}$ . This means
that taking $log_{a} \mathcal{R}_q$ repeatedly will yield the position of the next
bloom filter entry that needs to be incremented.

\begin{algorithm}
\KwIn{The compressed index sum $\mathcal{R}_q$}
\KwOut{Matched result $\mathcal{M}_q$ comprising a sequence of 0s, 1s and 2s}
$ a \gets 3 $ \;
$i \gets 0 $\;
\While{$\mathcal{R}_q > 0$}{
  $i \gets \log_a \mathcal{R}_q$ \;
  $\mathcal{R}_q \gets \mathcal{R}_q - a^{i}$ \;
  $\mathcal{M}_q [i] \gets \mathcal{M}_q [i] + 1 $ \;
}\Return{$\mathcal{M}_q$}\;
 \caption{Index entry decompression}
 \label{algo:decomp}
\end{algorithm}

The savings achieved using this algorithm can be evaluated using a simple theoretical
formulation. Suppose we use a 32-bit bloom filter and a 64-bit Pascal Paillier key.
Then for 1000 keywords, the data owner will create an index file with 1000 entries.
Then the size of the index file will be 32*64*1000/8 = 256KB. On the other hand,
after compression, the number returned per keyword will just have a size equal to the
size of the Paillier key, namely 64 bits. So the total data returned will be 
64*1000/8 = 8KB, a saving of over 95\%.
